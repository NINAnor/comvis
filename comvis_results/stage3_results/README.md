# Stage 3 results

**We selected Case A as a test case for Stage 3.** Case A represent monitoring of large ungulates (moose and reindeer) in Northern birch forest and is part of a long term monitoring design running in COAT (www.coat.no) since 2011. It consists of 24 cameras. Over the years two different camera models have been used (Scoutguard and Reconyx) and the acquisition mode has been changed from time lapse only in the early years to a combination of time lapse and motion sensor. The goal of the monitoring design is to quantify the occurrence of large ungulates visiting the forest plots in the different months of the year, in two contrasting grazing regimes. The cameras are active all year. The largest challenge in Case A is that a limited number of animals are captured in the course of a year. This is a typical challenge for passive camera trap designs. In Comvis we wished to explore whether it would be at all possible to train a classifier able to distinguish two relatively similar species (both large ungulates) with the relatively low number of images acquired within the monitoring design (a suboptimal sample size, but all images represent the local case condition, i.e., within-sample-prediction). We further wish to explore whether a classifier trained on crowd sourced images (large sample size, but not representing the local case context, i.e, out-of-sample prediction) would perform better that a locally trained classifier. If so, this could be a way forward for developing classifiers for species which are not captured by the thousands in NINA’s own monitoring designs.

The locally trained classifier was trained using ~200 moose objects and ~350 reindeer objects. The moose sample represents almost all the moose images collected during 7 years of monitoring.

The results from the confusion matrix of the test dataset show clearly that the locally trained classifier has a very poor performance. It is not able to distinguish reindeer from moose at all and classify all objects as reindeer. 

![](../../assets/testImg.png)

This clearly demonstrates that even a comparably well stocked (24 replicate cameras) and long term (10 years ++) monitoring design may fail to obtain enough images to train custom classifiers for low abundance target species. This will be a fairly common situation for small-intermediate monitoring designs in NINA. 

We proceeded to acquire a large sample of crowd sourced images from github. All records of moose from Norway, Finland and Sweden which were documented by an image were included in the search. Images of indirect evidence (e.g., carcasses, antlers, scats, tracks) were subsequently excluded, resulting in a sample of ~4200 moose images containing one or more moose objects. As a contrasting sample of “non-moose” we acquired a similar sized sample of other large ungulates (reindeer, red deer and roe deer). Currently we are implementing manual annotation of these images as well as a custom classifier for moose. These results are beyond the original intention of Comvis and will hence have to be continued in early 2024. But if the classifier performs well, using crowd sourced images could be a way forward for developing generic species level classifiers for other species which occur at relatively low abundance in NINAs monitoring designs.

